\chapter{Conclusões}
\label{cap:conclusoes}
Este trabalho mostrou que é possível reduzir ruído e ampliar cobertura na coleta de conteúdo relevante para desinformação combinando etapas simples e robustas de PLN com modelos modernos baseados em Transformers. Na sumarização, embora BERT-base, DistilBERT e SBERT-MiniLM tenham mantido proporções semelhantes do texto original, o SBERT destacou-se pelo melhor equilíbrio entre retenção semântica e custo computacional, tornando-o o candidato mais indicado para cenários de alto volume. Já o DistilBERT apareceu como uma modelo mais conservador, preservando incerteza e reduzindo risco de super-rotulagem, ao passo que o BERT-base priorizou a retenção de trechos factuais completos.

A principal contribuição metodológica foi a segmentação guiada por conjunções, mais especificamente pelo termo ``que''. Essa estratégia, de baixo custo e fácil implementação, recuperou conjuntos maiores e mais pertinentes de trechos quando comparada a termos manuais, além de superar abordagens baseadas apenas em aspas, que se mostraram pouco consistentes. Em dados de referência com dois clusters polarizados, a segmentação por ``que'' e os modelos BERT/sBERT comprimiram a classe ``não rotulado'' e reforçaram o contraste estrutural entre clusters (C0 mais ``com desinformação''; C1 mais ``sem desinformação''), enquanto o DistilBERT manteve distribuição um pouco mais próxima do retrato manual.

Na detecção de afirmações factuais, o XLM-R-Large-ClaimDetection alcançou desempenho competitivo mesmo fora do idioma de treino, com alta sensibilidade para sentenças relevantes (recall elevado) e menor precisão adequado à etapa de triagem automática. Em paralelo, embora o SVM tenha exibido acurácia nominal alta, sua utilidade prática foi limitada pela extração de textos pouco relevantes, sinalizando a importância de avaliar não apenas métricas agregadas, mas a aderência ao objetivo operacional (reduzir ruído mantendo o “sinal” de interesse).

Em síntese, o pipeline proposto, sumarização leve (preferencialmente com SBERT para escala), segmentação linguística simples (com “que”) e um classificador sensível para triagem (XLM-R), mostrou ganhos concretos de cobertura e eficiência sem depender de infraestrutura mais complexa. As evidências sugerem que ajustes de limiar, custos de classe e um filtro estrutural pós-classificação (por padrões discursivos ou regras de domínio) tendem a melhorar a precisão final, especialmente nos clusters mais ruidosos. Como limitações, permanecem as restrições de hardware para fine-tuning ideal e a transferência entre domínios/idiomas. Como trabalhos futuros, recomenda-se (i) calibrar thresholds com validação cruzada por cluster, (ii) empilhar filtros híbridos (regras + embeddings) após o XLM-R, (iii) testar empacotamento eficiente de sequências e knowledge distillation para reduzir custo. Esses passos devem fortalecer a aplicabilidade em monitoramento contínuo e acelerar respostas a campanhas desinformacionais em larga escala.
\section{Contribuições}
O projeto será realizado em laboratórios de informáticas localizados no Bloco A, torre
2 e no laboratório de Pesquisa LIRTE (Laboratório de Informações em Rede e Tecnologias
Educacionais) localizado no Bloco L, ambos laboratórios pertencentes à Universidade Federal
do ABC. Também será utilizado bases de dados públicos e diferentes softwares para fins de
análise, quantificação, comparação e classificação, com a orientação da Profª Drª Denise
Hideko Goya. Este trabalho contará com auxílio da Universidade Federal do ABC por meio da
disponibilização da rede para ser efetuada a pesquisa, tendo acesso a artigos voltados apenas à
comunidade acadêmica.

\section{Limitações}


\section{Trabalhos Futuros}


