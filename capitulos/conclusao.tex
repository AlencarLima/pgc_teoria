\chapter{Considerações Finais}
\label{cap:conclusoes}

Este trabalho mostrou que é possível reduzir ruído e ampliar cobertura na coleta de conteúdo relevante para desinformação combinando etapas simples de PLN com modelos modernos baseados em \textit{Transformers} e regex. Na sumarização, embora \textit{BERT-base}, \textit{DistilBERT} e \textit{SBERT-MiniLM} tenham mantido proporções semelhantes do texto original, o \textit{SBERT} destacou-se pelo melhor equilíbrio entre retenção semântica e custo computacional, tornando-o o candidato mais indicado para cenários de alto volume. Já o \textit{DistilBERT} apareceu como um modelo mais conservador, preservando incerteza e reduzindo risco de rotulagem excessiva, ao passo que o \textit{BERT-base} priorizou a retenção de trechos factuais completos.

A principal contribuição metodológica foi a segmentação guiada por conjunções, mais especificamente pelo termo ``que''. Essa estratégia, de baixo custo e fácil implementação, recuperou conjuntos maiores e mais pertinentes de trechos quando comparada a termos manuais, além de superar abordagens baseadas apenas em aspas, que se mostraram pouco consistentes. Em dados de referência com dois \textit{clusters} polarizados, a segmentação por ``que'' e os modelos \textit{BERT}/\textit{sBERT} comprimiram a classe ``não rotulado'' e reforçaram o contraste entre \textit{clusters} (C0 mais ``com desinformação''; C1 mais ``sem desinformação''), enquanto o \textit{DistilBERT} manteve distribuição um pouco mais próxima do retrato manual.

Na detecção de afirmações factuais, o \textit{XLM-R-Large-ClaimDetection} alcançou desempenho satisfatório mesmo fora do idioma de treino, com alta sensibilidade para sentenças relevantes (\textit{recall} elevado) e menor precisão adequada à etapa de triagem automática. Em paralelo, o modelo \textit{SVM} exibiu uma acurácia moderada; sua utilidade prática se destaca sobretudo pelo baixo custo computacional, o que o torna adequado como linha de base em cenários com recursos limitados.

Foram utilizadas bases de dados públicas para fins de análise, quantificação, comparação e classificação, com orientação da Profª Drª Denise Hideko Goya. A disponibilização da rede institucional e do acesso a artigos voltados à comunidade acadêmica contribuiu para a elaboração do \textit{pipeline} proposto e possibilitou testar, em ambiente controlado, cenários de monitoramento em larga escala.

Em síntese, o \textit{pipeline} proposto, sumarização leve (preferencialmente com \textit{SBERT} para melhor escalabilidade), segmentação linguística simples (com ``que'') e um classificador sensível para triagem (\textit{XLM-R}), mostrou ganhos relevantes de cobertura e eficiência sem depender de infraestrutura mais complexa.

\section{Limitações}

Apesar dos resultados positivos, algumas limitações importantes permaneceram. Em primeiro lugar, há restrições de hardware para realização de um \textit{fine-tuning} ideal dos modelos de maior porte, em especial do \textit{XLM-R-Large-ClaimDetection}. Essas limitações de capacidade computacional restringiram os experimentos à utilização de modelos pré-treinados, sem ajuste fino mais aprofundado aos dados específicos em português.

Em segundo lugar, o estudo depende de um modelo pré-treinado majoritariamente em inglês para tarefas aplicadas a textos em português. Essa diferença linguística pode impactar a eficácia do modelo, especialmente em nuances culturais e contextuais presentes na desinformação política local apesar de ser utilizado um modelo multilíngue.

\section{Trabalhos Futuros}

Como perspectiva para trabalhos futuros, recomenda-se, em primeiro lugar, calibrar \textit{thresholds} com validação cruzada por \textit{cluster}, de forma a adaptar os pontos de corte às características específicas de grupos de mensagens com perfis distintos. Em segundo lugar, sugere-se empilhar filtros híbridos (regras + \textit{embeddings}) após o \textit{XLM-R}, combinando a interpretabilidade de regras linguísticas com o poder de generalização de representações densas. Em terceiro lugar, é relevante testar esquemas de empacotamento eficiente de sequências e técnicas de \textit{knowledge distillation} para reduzir custo computacional, fortalecendo a aplicabilidade do \textit{pipeline} em cenários de monitoramento contínuo e em tempo quase real.

Além disso, seria relevante realizar uma comparação sistemática entre a Abordagem Linguística implementada neste estudo e modelos baseados em Abordagem de Redes descritos na literatura. A primeira foca na análise do conteúdo de mensagens enganosas, identificando padrões linguísticos que indicam engano, como o uso de pronomes, conjunções e palavras associadas a emoções negativas. Já a Abordagem de Redes utiliza informações de rede, por exemplo, metadados de mensagens ou consultas estruturadas em redes de conhecimento, para calcular medidas agregadas de engano~\cite{ADDConroy}. Ambas as abordagens tendem a incorporar técnicas de aprendizado de máquina para treinar classificadores especializados, e uma comparação sistemática poderia esclarecer em quais contextos cada uma delas apresenta vantagens relativas.

Adicionalmente, um ponto relevante consiste em realizar o \textit{fine-tuning} do modelo \textit{XLM-R-Large-ClaimDetection} para o português e comparar seu desempenho tanto com a abordagem linguística proposta neste trabalho quanto com modelos baseados em redes. Por conta das limitações de hardware enfrentadas durante este estudo, o \textit{fine-tuning} do \textit{XLM-R-Large-ClaimDetection} não foi possível, o que restringiu a análise ao uso do modelo pré-treinado em inglês. Portanto, realizar esse ajuste fino para o português e avaliar seu desempenho em comparação com outras abordagens configura um passo importante para aprofundar a compreensão sobre a eficácia dos modelos de detecção de desinformação em diferentes idiomas e contextos.

Por fim, recomenda-se explorar processos de sumarização com a utilização de LLMs (\textit{Large Language Models}) para avaliar se esses modelos conseguem capturar melhor o contexto e nuances do texto original, potencialmente melhorando a retenção semântica em comparação com os modelos baseados em \textit{Transformers} utilizados neste estudo.
