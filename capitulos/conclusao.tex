\chapter{Considerações Finais}
\label{cap:conclusoes}

Este trabalho mostrou que é possível reduzir ruído e ampliar cobertura na coleta de conteúdo relevante para desinformação combinando etapas simples e robustas de PLN com modelos modernos baseados em Transformers. Na sumarização, embora BERT-base, DistilBERT e SBERT-MiniLM tenham mantido proporções semelhantes do texto original, o SBERT destacou-se pelo melhor equilíbrio entre retenção semântica e custo computacional, tornando-o o candidato mais indicado para cenários de alto volume. Já o DistilBERT apareceu como um modelo mais conservador, preservando incerteza e reduzindo risco de super-rotulagem, ao passo que o BERT-base priorizou a retenção de trechos factuais completos.

A principal contribuição metodológica foi a segmentação guiada por conjunções, mais especificamente pelo termo ``que''. Essa estratégia, de baixo custo e fácil implementação, recuperou conjuntos maiores e mais pertinentes de trechos quando comparada a termos manuais, além de superar abordagens baseadas apenas em aspas, que se mostraram pouco consistentes. Em dados de referência com dois clusters polarizados, a segmentação por ``que'' e os modelos BERT/sBERT comprimiram a classe ``não rotulado'' e reforçaram o contraste estrutural entre clusters (C0 mais ``com desinformação''; C1 mais ``sem desinformação''), enquanto o DistilBERT manteve distribuição um pouco mais próxima do retrato manual.

Na detecção de afirmações factuais, o XLM-R-Large-ClaimDetection alcançou desempenho competitivo mesmo fora do idioma de treino, com alta sensibilidade para sentenças relevantes (recall elevado) e menor precisão adequado à etapa de triagem automática. Em paralelo, o modelo SVM exibiu uma acurácia moderada, sua utilidade prática se destaca sobretudo baixo custo computacional, o que o torna adequado como linha de base em cenários com recursos limitados.

Do ponto de vista institucional e de infraestrutura, o projeto foi viabilizado pelos laboratórios de informática localizados no Bloco A, torre 2, e pelo laboratório de pesquisa LIRTE (Laboratório de Informações em Rede e Tecnologias Educacionais), situado no Bloco L, ambos pertencentes à Universidade Federal do ABC. Também foram utilizadas bases de dados públicas e diferentes softwares para fins de análise, quantificação, comparação e classificação, com orientação da Profª Drª Denise Hideko Goya. A disponibilização da rede institucional e do acesso a artigos voltados à comunidade acadêmica foi essencial para consolidar o pipeline proposto e testar, em ambiente controlado, cenários de monitoramento em larga escala.

Em síntese, o pipeline proposto, sumarização leve (preferencialmente com SBERT para escala), segmentação linguística simples (com ``que'') e um classificador sensível para triagem (XLM-R), mostrou ganhos concretos de cobertura e eficiência sem depender de infraestrutura mais complexa. As evidências sugerem que ajustes de limiar, custos de classe e um filtro estrutural pós-classificação (por padrões discursivos ou regras de domínio) tendem a melhorar a precisão final, especialmente nos clusters mais ruidosos. Como limitações, permanecem as restrições de hardware para fine-tuning ideal, a dependência de um modelo pré-treinado em inglês para tarefas em português e os desafios de transferência entre domínios/idiomas, o que limita a generalização imediata para outros contextos.

Como perspectiva para trabalhos futuros, recomenda-se (i) calibrar thresholds com validação cruzada por cluster, (ii) empilhar filtros híbridos (regras + embeddings) após o XLM-R e (iii) testar empacotamento eficiente de sequências e \textit{knowledge distillation} para reduzir custo computacional, fortalecendo a aplicabilidade em monitoramento contínuo. Além disso, seria relevante realizar uma comparação sistemática entre a Abordagem Linguística implementada neste estudo e modelos baseados em Abordagem de Redes descritos na literatura. A primeira foca na análise do conteúdo de mensagens enganosas, identificando padrões linguísticos que indicam engano, como o uso de pronomes, conjunções e palavras associadas a emoções negativas. Já a Abordagem de Redes utiliza informações de rede, por exemplo, metadados de mensagens ou consultas estruturadas em redes de conhecimento, para calcular medidas agregadas de engano.~\cite{ADDConroy} Ambas as abordagens tendem a incorporar técnicas de aprendizado de máquina para treinar classificadores especializados.

Adicionalmente, um ponto relevante consiste em realizar o \textit{fine-tuning} do modelo XLM-R-Large-ClaimDetection para o português e comparar seu desempenho tanto com a abordagem linguística proposta neste trabalho quanto com modelos baseados em redes. Por conta das limitações de hardware enfrentadas durante este estudo, o \textit{fine-tuning} do XLM-R-Large-ClaimDetection não foi possível, o que restringiu a análise ao uso do modelo pré-treinado em inglês. Portanto, realizar esse ajuste fino para o português e avaliar seu desempenho em comparação com outras abordagens configura um passo importante para aprofundar a compreensão sobre a eficácia dos modelos de detecção de desinformação em diferentes idiomas e contextos.
