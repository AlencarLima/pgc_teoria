\chapter{Resultados e Discussões}
\label{cap:resultados}
\section{Resultados Obtidos}

\subsection{Sumarização}
Para o primeiro processo de sumarização automática para redução de ruído, três modelos foram avaliados: BERT-base, DistilBERT e SBERT-MiniLM. Em todos os casos, os resumos ficaram entre 25\% e 27\% do tamanho do texto original conforme mostrado na Figura~\ref{fig:compression-ratio}, sem diferenças expressivas de compressão entre os modelos, com leve tendência do DistilBERT a produzir resumos mais concisos e do SBERT-MiniLM a manter textos um pouco maiores.

\begin{figure}[ht] % ou [!htb] se preferir deixar o LaTeX decidir
    \centering
    \includegraphics[width=1\textwidth]{figs/compression_ratio.png} % coloque o arquivo na pasta escolhida
    \caption{Compression ratio médio (|resumo|/|original|) por modelo.}
    \label{fig:compression-ratio}
    \legend{\footnotesize Fonte: elaboração própria.} % abnTeX2
\end{figure}

Quando se observa apenas a preservação de trechos factuais, BERT-base e SBERT-MiniLM mantiveram cerca de 25\% a 26\% de conteúdo classificado como factual, superando o DistilBERT, que ficou em torno de 22\% conforme mostrado na Figura~\ref{fig:factualidade}. Em termos de retenção de tópicos centrais, medida pelo índice de Jaccard entre as palavras-chave do original e do resumo, o SBERT-MiniLM apresentou o melhor resultado (0,22), seguido muito de perto pelo BERT-base (0,21), enquanto o DistilBERT apresentou desempenho inferior (0,14). Da mesma forma, quando a similaridade textual foi medida por uma métrica de similaridade (TF-IDF/cosseno), o SBERT-MiniLM obteve o maior valor (0,64), superando ligeiramente o BERT-base e o DistilBERT, ambos com 0,61. No entanto, o tempo de processamento mostrou diferenças marcantes: o BERT-base demandou em média mais de 22 segundos por texto, o DistilBERT cerca de 3 segundos e o SBERT-MiniLM pouco mais de 1 segundo, o que torna o último mais adequado a cenários de grande volume.

\begin{figure}[ht] % ou [!htb] se preferir deixar o LaTeX decidir
    \centering
    \includegraphics[width=1\textwidth]{figs/factual_graph.png} % coloque o arquivo na pasta escolhida
    \caption{Factualidade \% por modelo.}
    \label{fig:factualidade}
    \legend{\footnotesize Fonte: elaboração própria.} % abnTeX2
\end{figure}

\subsection{Segmentação baseada em conjunções}
Os resultados da abordagem de segmentação baseada no termo ``que'' demonstraram sua eficácia. Nas 29 amostras de notícias provenientes de agências de checagem de fatos, a segmentação baseada no termo ``que'' resultou em textos altamente relevantes, evidenciando ser uma técnica interessante de segmentação para textos contidos em notícias. Este método apresenta a vantagem de não exigir grande processamento, sendo uma alternativa eficiente para identificar informações relevantes em grandes volumes de texto.

Além disso, a aplicação desse método em \textit{clusters} polarizados mostrou resultados significativos. Para o $cluster_0$, foi possível obter 2.060 tuítes relevantes, em comparação com os 2.056 tuítes obtidos utilizando termos-chave criados manualmente. Já no $cluster_1$, foram extraídos 1.089 tuítes, superando os 781 obtidos com termos-chave definidos manualmente. Exemplos de textos retornados por esse método incluem: ``aponta que apertar `confirma' durante a tela `confira seu voto' anula o voto'' e ``usou o plenário da câmara federal para propagar informações falsas sobre a pandemia, como mostrou uma reportagem publicada pela Lupa em dezembro do ano passado''.  Esses resultados demonstram que a segmentação baseada em conjunções, como o termo ``que'', pode ser mais eficaz do que abordagens manuais tradicionais, ampliando a abrangência e precisão na identificação de conteúdos relevantes para análise de desinformação.

A aplicação do modelo XLM-R-Large-ClaimDetection nos dados de debates presidenciais dos EUA ~\cite{dbClaim}, adaptados ao contexto português, apresentou resultados promissores na tarefa de classificação de afirmações factuais. O modelo alcançou uma acurácia de 0.88, mostrando boa performance mesmo considerando as diferenças linguísticas entre os dados testados em português e o treinamento original em inglês.

Por meio da utilização de uma matriz de confusão foi possível verificar que o modelo classificou corretamente a maioria das afirmações factuais e não factuais, com 680 previsões corretas para sentenças factuais não relevantes e 232 para as sentenças factuais importantes. Porém, houve dificuldades de diferenciar categorias factuais não relevantes, sendo classificadas incorretamente 114 sentenças das 1034 presentes no database.

Esses resultados são demonstrados no relatório de classificação, que apresentou um desempenho muito elevado para as sentenças factuais não relevantes, com \textit{precisão} de 0.99 e \textit{recall} de 0.86, conforme dados \autoref{tab:resultados_pt}. Já para as sentenças factuais relevantes, a \textit{precisão} foi de 0.67, enquanto o \textit{recall} atingiu um valor consideravelmente alto de 0.97, evidenciando a capacidade do modelo em identificar corretamente a maioria das afirmações importantes, ainda que tenha apresentado menor precisão nessa categoria.

Em comparação com o modelo original treinado em inglês, que obteve uma acurácia de 0.90, os resultados em português apresentaram uma leve queda. No estudo original, o modelo foi capaz de classificar afirmações factuais e não factuais com equilíbrio entre \textit{precisão} e \textit{recall}, alcançando valores de 0.90 em ambas as métricas, conforme apresentado na \autoref{tab:resultados_en}.

\begin{table}[ht]
    \centering
    \caption{Resultados do modelo XLM-R-Large-ClaimDetection em português}
    \label{tab:resultados_pt}
    \begin{tabular}{lccc}
        \toprule
        Classe & Precision & Recall & F1-Score \\
        \midrule
        Unimportant Factual Sentence (UFS) & 0.99 & 0.86 & 0.92 \\
        Important Factual Sentence (IFS)   & 0.67 & 0.97 & 0.79 \\
        \midrule
        Acurácia Geral & \multicolumn{3}{c}{0.88} \\
        \bottomrule
    \end{tabular}
\end{table}

\begin{table}[ht]
    \centering
    \caption{Resultados originais do modelo XLM-R-Large-ClaimDetection em inglês}
    \label{tab:resultados_en}
    \begin{tabular}{lccc}
        \toprule
        Classe       & Precision & Recall & F1-Score \\
        \midrule
        Factual      & 0.88      & 0.92   & 0.90     \\
        Non-Factual  & 0.92      & 0.88   & 0.90     \\
        \midrule
        Acurácia Geral & \multicolumn{3}{c}{0.90} \\
        \bottomrule
    \end{tabular}
\end{table}

O baixo rendimento em encontrar sentenças factuais importantes (IFS) pode ser atribuído ao fato de o treinamento não ter sido realizado de forma ideal, devido a limitações de hardware. A performance alcançada, ainda assim, destaca a utilidade do modelo XLM-R-Large como ferramenta para filtragem e segmentação de grandes volumes de texto, facilitando a identificação de informações relevantes para análises de desinformação e processos de verificação de fatos.

Apesar de apresentar métricas menos eficientes, o modelo conseguiu extrair textos relevantes das 29 notícias analisadas conforme pode ser visto na \autoref{tab:exemplo-6x5}. Com textos resumidos pelo BERT, foram retornados 2.391 tuítes no $cluster_0$ e 1.333 no $cluster_1$, já para o DistilBERT (dBERT), 1.670 e 928, respectivamente e com o SBERT, 2.040 e 1.234. Entre as frases relevantes extraídas, destacam-se exemplos como: “o TSE (Tribunal Superior Eleitoral) não testou a segurança das urnas para as eleições de 2022”. No entanto, o modelo também retornou frases menos relevantes, como: “no Telegram disseminam informações falsas sobre o”, “estão registrados na seção” e “circulam nas redes sociais (veja aqui)”. Esse comportamento reforça a necessidade de aprimorar a precisão na filtragem de conteúdo, evitando a extração de dados não essenciais, o que pode aumentar o tempo de processamento e reduzir a eficiência geral do sistema.

\subsection{Segmentação baseada em aspas}
Para o método envolvendo apenas aspas, houve retorno de frases para apenas 5 das 29
notícias analisadas, demonstrando sua baixa eficácia na identificação de informações relevantes. Entre os textos retornados estavam exemplos como: ``Outro exemplo citado por ele é no caso de a totalização envolver, hipoteticamente, apenas duas cidades'', além de termos como ``banco nacional do brasil'', ``sala escura'' e ``vão para as nuvens''. Embora algumas frases tenham relevância contextual, o método não foi consistente o suficiente para ser amplamente aplicado, destacando a necessidade de estratégias mais eficazes para análise desse tipo de dado.

\subsection{Classificação de afirmações factuais com XLM-R-Large-ClaimDetection}
A aplicação do modelo XLM-R-Large-ClaimDetection apresentou acurácia de 0,88 em português, com bom 	extit{recall} para sentenças factuais importantes (0,97), mas menor precisão (0,67), o que indica tendência a recuperar quase tudo o que é relevante, ao custo de trazer alguns itens não essenciais.

\subsection{Comparação com o SVM}
O modelo SVM apresenta uma acurácia global moderada, em torno de 0,79. A classe 0 obteve \textit{precision} de 0,85 e \textit{recall} de 0,83, enquanto a classe 1, associada às sentenças factuais/relevantes, alcançou \textit{precision} de 0,69 e \textit{f1-score} de 0,71, conforme \autoref{tab:resultados_svm}. Esses valores indicam que o modelo é capaz de capturar uma parcela significativa das sentenças de interesse, embora ainda com ocorrência de falsos positivos e perda de algumas sentenças relevantes. Na prática, isso significa que a filtragem contribui para reduzir o volume de texto a ser analisado. Contudo, a presença de textos menos relevantes entre os resultados sugere que o modelo SVM pode beneficiar-se de ajustes adicionais ou da combinação com outras técnicas de filtragem para melhorar a qualidade do conteúdo extraído.

\begin{table}[ht]
    \centering
    \caption{Resultados do SVM em português}
    \label{tab:resultados_svm}
    \begin{tabular}{lccc}
        \toprule
        Classe        & Precision & Recall & F1-Score \\
        \midrule
        Factual      & 0.6903    & 0.7323 & 0.7107 \\
        Non-Factual  & 0.8538    & 0.8263 & 0.8398 \\
        \midrule
        Acurácia geral & \multicolumn{3}{c}{0.7938} \\
        \bottomrule
    \end{tabular}
\end{table}

\section{Comparação de Classificação}
Pode-se notar que pelo gráfico de Distribuição de Desinformação em tweets presentes no Cluster 0 (Figura~\ref{fig:tweets_cluster_0}), no método manual de referência o C0 apresenta 33{,}4\% de tweets classificados como com desinformação, 6{,}0\% como sem desinformação e 60{,}5\% como não rotulados. Com a aplicação dos modelos, todos os métodos de segmentação e classificação aumentaram a proporção de tweets classificados como com desinformação em relação ao método manual: no DistilBERT, essa proporção sobe para 47{,}5\%, enquanto SBERT, segmentação por ``que'', BERT e SVM deslocam a classe com desinformação'' para a faixa de 55--62\%, com a classe sem desinformação avançando para cerca de 9--13\%. O DistilBERT foi o que apresentou o menor aumento, seguido pelo SBERT, segmentação por ``que'', BERT e SVM, que tiveram aumentos mais expressivos. Isso indica que esses métodos são mais agressivos na identificação de tweets com desinformação, o que pode ser benéfico para capturar mais conteúdo relevante, mas também pode aumentar o risco de falsos positivos.

Já para o Cluster 1 (Figura~\ref{fig:tweets_cluster_1}), no método manual de referência 8{,}4\% dos tweets são classificados como com desinformação, 28{,}6\% como sem desinformação e 63{,}0\% permanecem não rotulados''. Com os modelos, todos os métodos também aumentaram a proporção de tweets classificados como sem desinformação em comparação com o método manual, elevando essa classe para a faixa de 42--54\% e a classe com desinformação para 15--17\%, ao mesmo tempo em que comprimem a fração não rotulado para aproximadamente 29--43\%, abaixo dos 63{,}0\% do cenário manual. Novamente, o DistilBERT apresentou o menor aumento, seguido pela segmentação por ``que'', SBERT, BERT e SVM. Isso sugere que esses métodos são eficazes na identificação de tweets sem desinformação.
% Os gráficos de \textit{tweets} apresentados nas Figuras~\ref{fig:tweets-graph-manual}, \ref{fig:tweets-graph-bert}, \ref{fig:tweets-graph-dbert}, \ref{fig:tweets-graph-sbert} e \ref{fig:tweets-graph-que}, \ref{fig:tweets-graph-svm}, obtidos no processo com termos-chave definidos manualmente e por modelos, evidenciam que ambos os \textit{clusters} são dominados por itens não rotulados (C0: 60{,}5\% e C1: 63{,}0\% no caso manual), com desinformação mais presente no Cluster 0 (33{,}4\%) do que no Cluster 1 (8{,}4\%). Já a classe sem desinformação é minoritária no C0 (6{,}0\%) e relativamente mais frequente no C1 (28{,}6\%). Esse é o retrato de referência fornecido pela Figura~\ref{fig:tweets-graph-manual}: o C0 concentra uma fração relevante de \textit{tweets} com desinformação, enquanto o C1 reúne mais \textit{tweets} sem desinformação, ainda que em ambos haja grande massa de ``não rotulada''.

% Nas Figuras~\ref{fig:tweets-graph-bert}, \ref{fig:tweets-graph-dbert}, \ref{fig:tweets-graph-sbert}, \ref{fig:tweets-graph-que} e \ref{fig:tweets-graph-svm}, que correspondem às segmentações via BERT, DistilBERT, sBERT, termos baseados em ``que'' e o modelo de SVM, observa-se que todos os modelos preservam esse contraste com relação aos dados retornados pelo formato manual (C0 com maior proporção ``com desinformação'' e C1 com maior proporção ``sem desinformação''), porém reduzem intensamente a classe ``não rotulado''. No Cluster 0, BERT, sBERT, segmentação por ``que'' e SVM (Figuras~\ref{fig:tweets-graph-bert}, \ref{fig:tweets-graph-sbert}, \ref{fig:tweets-graph-que} e \ref{fig:tweets-graph-svm}) deslocam muitos exemplos para ``com desinformação'' (na faixa de 55--62\%), enquanto o DistilBERT (Figura~\ref{fig:tweets-graph-dbert}) é o que menos eleva (47{,}5\%), ainda assim acima do manual (33{,}4\%). A classe sem desinformação também cresce em todos (9--13\% vs.\ 6{,}0\%). No Cluster 1, o padrão se repete: sem desinformação sobe para 42--54\% (vs.\ 28{,}6\%) e com desinformação para 15--17\% (vs.\ 8{,}4\%), comprimindo ``não rotulado'' para 29--43\% ficando abaixo dos 63\% do manual.

Em termos de comparação relativa ao manual, o DistilBERT tende a ficar mais próximo, sendo o que menos retira a classe ``não rotulado'' (C0: 43{,}3\% e C1: 43{,}2\%). BERT, sBERT e ``que'' tornam as classes rotuladas mais assertivas, principalmente \textit{com desinformação} no C0 e \textit{sem desinformação} no C1. Entre os resultados, o DistilBERT apresenta o desvio mais contido, enquanto BERT/sBERT/``que'' oferecem maior assertividade com menor conservadorismo.

Os gráficos de retuítes, exibidos nas Figuras~\ref{fig:retuites_cluster_0} e \ref{fig:retuites_cluster_1}, mostram padrões semelhantes aos observados nos gráficos de tweets. No método manual de referência, o Cluster 0 (C0) apresenta 44{,}0\% de retuítes classificados como ``com desinformação'', 11{,}2\% como ``sem desinformação'' e 44{,}9\% como ``não rotulados''. Com a aplicação dos modelos, todos os métodos de segmentação e classificação aumentaram a proporção de retuítes classificados como ``com desinformação'' em relação ao método manual: no DistilBERT, essa proporção sobe para 57{,}0\%, para SBERT, segmentação por ``que'', BERT e SVM deslocam a classe ``com desinformação'' para a faixa de 57--63\%, com a classe ``sem desinformação'' avançando para cerca de 5--13\%. O DistilBERT foi o único que apresentou um decréscimo na classe ``sem desinformação'', onde houve apenas 2154 retuítes para ``sem desinformação'' em comparação aos 4493 no método manual. Os outros métodos aumentaram essa classe em relação ao manual mas de forma pouco significativa.

Já para o Cluster 1 (Figura~\ref{fig:retuites_cluster_1}), no método manual de referência 1{,}3\% dos retuítes são classificados como ``com desinformação'', 44{,}5\% como ``sem desinformação'' e 54{,}3\% permanecem ``não rotulados''. Com os modelos, todos os métodos também aumentaram a proporção de retuítes classificados como ``sem desinformação'' em comparação com o método manual, elevando essa classe para a faixa de 51--72\%, ao mesmo tempo em que comprimem a fração ``não rotulado'' para aproximadamente 24--54\%, abaixo dos 62{,}6\% do cenário manual. Novamente, o DistilBERT apresentou o menor aumento, seguido pela segmentação por ``que'', SBERT, BERT e SVM. Já a classe ``com desinformação'' apresentou um aumento porcentual menos significativo em relação ao manual, ficando na faixa de 1{,}6--2{,}3\%, tendo o DistilBERT e SBERT bem próximos ao obtido manualmente (1{,}6 e 1{,}7\% respectivamente).

% Os gráficos de retuítes, exibidos nas Figuras~\ref{fig:retuites-graph-manual}, \ref{fig:retuites-graph-bert}, \ref{fig:retuites-graph-dbert}, \ref{fig:retuites-graph-sbert}, \ref{fig:retuites-graph-que} e \ref{fig:retuites-graph-svm}, confirmam o contraste estrutural observado no retrato de referência: o Cluster 0 (C0) é o polo de desinformação, enquanto o Cluster 1 (C1) concentra mais conteúdos sem desinformação. No manual (Figura~\ref{fig:retuites-graph-manual}), C0 aparece dividido entre desinformação e não rotulados, com ``sem desinformação'' minoritário. Já C1 combina forte presença de ``sem desinformação'' com uma massa considerável de itens não rotulados e quase nenhuma desinformação.

% Nas Figuras~\ref{fig:retuites-graph-bert}, \ref{fig:retuites-graph-sbert} e \ref{fig:retuites-graph-que}, que mostram respectivamente BERT, sBERT e a segmentação por ``que'', a diferença central está menos na hierarquia entre classes e mais na magnitude das proporções. Esses três métodos reduzem de forma significativa a fatia de ``não rotulado'', ao mesmo tempo em que aumentam as classes rotuladas. O efeito é notório em C0, onde essas abordagens deslocam um grande contingente para ``com desinformação'', reforçando a vocação do cluster, Em C1, o movimento simétrico impulsiona ``sem desinformação''. Em termos comunicacionais, esses métodos tornam os gráficos de retuítes mais assertivos e menos conservadores, produzindo leituras mais decididas sobre o conteúdo que circula por meio dos retuítes.

O DistilBERT atua como um freio nessa tendência. Ele preserva uma parcela maior de ``não rotulado'' em ambos os clusters, aproximando a distribuição dos retuítes do que se vê no manual. Em C0, isso se traduz em um crescimento mais moderado da classe ``com desinformação''. Em C1, significa manter, em nível relativamente alto, a incerteza capturada pela classe ``não rotulado'', e, portanto, menor risco de super-rotulagem. Em resumo, entre os modelos testados, DistilBERT apresenta o desvio mais contido em relação ao padrão manual, enquanto BERT, sBERT e ``que'' fornecem leituras mais assertivas.

Do ponto de vista analítico, a opção entre assertividade e fidelidade orienta a escolha. Para  reproduzir com maior proximidade o retrato
manual e controlar falsos positivos nos retuítes, DistilBERT é mais similar e retorna resultados mais conservadores. Para maximizar a rotulagem e obter uma visão mais clara dos polos de desinformação e informação correta, BERT, sBERT e a segmentação por ``que'' são mais eficazes.
\begin{figure}[H] % ou [!htb] se preferir deixar o LaTeX decidir
    \centering
    \includegraphics[width=1\textwidth]{figs/cluster_0_tweets.png} % coloque o arquivo na pasta escolhida
    \caption{Distribuição de Desinformação em tweets por abordagem para o Cluster 0 - Mês de outubro/2022}
    \label{fig:tweets_cluster_0}
    \legend{\footnotesize Fonte: elaboração própria.} % abnTeX2
\end{figure}
\begin{figure}[H] % ou [!htb] se preferir deixar o LaTeX decidir
    \centering
    \includegraphics[width=1\textwidth]{figs/cluster_1_tweets.png} % coloque o arquivo na pasta escolhida
    \caption{Distribuição de Desinformação em tweets por abordagem para o Cluster 1 - Mês de outubro/2022}
    \label{fig:tweets_cluster_1}
    \legend{\footnotesize Fonte: elaboração própria.} % abnTeX2
\end{figure}
\begin{figure}[H] % ou [!htb] se preferir deixar o LaTeX decidir
    \centering
    \includegraphics[width=1\textwidth]{figs/cluster_0_retuites.png} % coloque o arquivo na pasta escolhida
    \caption{Distribuição de Desinformação em retuítes por abordagem para o Cluster 0 - Mês de outubro/2022}
    \label{fig:retuites_cluster_0}
    \legend{\footnotesize Fonte: elaboração própria.} % abnTeX2
\end{figure}
\begin{figure}[H] % ou [!htb] se preferir deixar o LaTeX decidir
    \centering
    \includegraphics[width=1\textwidth]{figs/cluster_1_retuites.png} % coloque o arquivo na pasta escolhida
    \caption{Distribuição de Desinformação em retuítes por abordagem para o Cluster 1 - Mês de outubro/2022}
    \label{fig:retuites_cluster_1}
    \legend{\footnotesize Fonte: elaboração própria.} % abnTeX2
\end{figure}
% \begin{figure}[H] % ou [!htb] se preferir deixar o LaTeX decidir
%     \centering
%     \includegraphics[width=1\textwidth]{figs/tweets_graph_manual.png} % coloque o arquivo na pasta escolhida
%     \caption{Gráfico tweets com desinformação em relação aos retuítes de cada
% cluster obtidos com termos-chave manuais - Mês de outubro/2022}
%     \label{fig:tweets-graph-manual}
%     \legend{\footnotesize Fonte: elaboração própria.} % abnTeX2
% \end{figure}
% \begin{figure}[H] % ou [!htb] se preferir deixar o LaTeX decidir
%     \centering
%     \includegraphics[width=1\textwidth]{figs/tweets_graph_bert.png} % coloque o arquivo na pasta escolhida
%     \caption{Gráfico tweets com desinformação em relação aos retuítes de cada
% cluster obtidos com termos-chave BERT - Mês de outubro/2022}
%     \label{fig:tweets-graph-bert}
%     \legend{\footnotesize Fonte: elaboração própria.} % abnTeX2
% \end{figure}
% \begin{figure}[H] % ou [!htb] se preferir deixar o LaTeX decidir
%     \centering
%     \includegraphics[width=1\textwidth]{figs/tweets_graph_dbert.png} % coloque o arquivo na pasta escolhida
%     \caption{Gráfico tweets com desinformação em relação aos retuítes de cada
% cluster obtidos com termos-chave DistilBERT - Mês de outubro/2022}
%     \label{fig:tweets-graph-dbert}
%     \legend{\footnotesize Fonte: elaboração própria.} % abnTeX2
% \end{figure}
% \begin{figure}[H] % ou [!htb] se preferir deixar o LaTeX decidir
%     \centering
%     \includegraphics[width=1\textwidth]{figs/tweets_graph_sbert.png} % coloque o arquivo na pasta escolhida
%     \caption{Gráfico tweets com desinformação em relação aos retuítes de cada
% cluster obtidos com termos-chave sBERT - Mês de outubro/2022}
%     \label{fig:tweets-graph-sbert}
%     \legend{\footnotesize Fonte: elaboração própria.} % abnTeX2
% \end{figure}
% \begin{figure}[H] % ou [!htb] se preferir deixar o LaTeX decidir
%     \centering
%     \includegraphics[width=1\textwidth]{figs/tweets_graph_que.png} % coloque o arquivo na pasta escolhida
%     \caption{Gráfico tweets com desinformação em relação aos retuítes de cada
% cluster obtidos com termos-chave baseados em ``que'' - Mês de outubro/2022}
%     \label{fig:tweets-graph-que}
%     \legend{\footnotesize Fonte: elaboração própria.} % abnTeX2
% \end{figure}
% \begin{figure}[H] % ou [!htb] se preferir deixar o LaTeX decidir
%     \centering
%     \includegraphics[width=1\textwidth]{figs/tweets_graph_svm.png} % coloque o arquivo na pasta escolhida
%     \caption{Gráfico tweets com desinformação em relação aos retuítes de cada
% cluster obtidos com termos-chave SVM - Mês de outubro/2022}
%     \label{fig:tweets-graph-svm}
%     \legend{\footnotesize Fonte: elaboração própria.} % abnTeX2
% \end{figure}

 
% \begin{figure}[H] % ou [!htb] se preferir deixar o LaTeX decidir
%     \centering
%     \includegraphics[width=1\textwidth]{figs/retuites_graph_manual.png} % coloque o arquivo na pasta escolhida
%     \caption{Gráfico dos retuítes de tweets com desinformação em relação aos retuítes de cada
% cluster obtidos com termos-chave manuais - Mês de outubro/2022}
%     \label{fig:retuites-graph-manual}
%     \legend{\footnotesize Fonte: elaboração própria.} % abnTeX2
% \end{figure}
% \begin{figure}[H] % ou [!htb] se preferir deixar o LaTeX decidir
%     \centering
%     \includegraphics[width=1\textwidth]{figs/retuites_graph_bert.png} % coloque o arquivo na pasta escolhida
%     \caption{Gráfico dos retuítes de tweets com desinformação em relação aos retuítes de cada
% cluster obtidos com termos-chave BERT - Mês de outubro/2022}
%     \label{fig:retuites-graph-bert}
%     \legend{\footnotesize Fonte: elaboração própria.} % abnTeX2
% \end{figure}
% \begin{figure}[H] % ou [!htb] se preferir deixar o LaTeX decidir
%     \centering
%     \includegraphics[width=1\textwidth]{figs/retuites_graph_dbert.png} % coloque o arquivo na pasta escolhida
%     \caption{Gráfico dos retuítes de tweets com desinformação em relação aos retuítes de cada
% cluster obtidos com termos-chave DistilBERT - Mês de outubro/2022}
%     \label{fig:retuites-graph-dbert}
%     \legend{\footnotesize Fonte: elaboração própria.} % abnTeX2
% \end{figure}
% \begin{figure}[H] % ou [!htb] se preferir deixar o LaTeX decidir
%     \centering
%     \includegraphics[width=1\textwidth]{figs/retuites_graph_sbert.png} % coloque o arquivo na pasta escolhida
%     \caption{Gráfico dos retuítes de tweets com desinformação em relação aos retuítes de cada
% cluster obtidos com termos-chave sBERT - Mês de outubro/2022}
%     \label{fig:retuites-graph-sbert}
%     \legend{\footnotesize Fonte: elaboração própria.} % abnTeX2
% \end{figure}
% \begin{figure}[H] % ou [!htb] se preferir deixar o LaTeX decidir
%     \centering
%     \includegraphics[width=1\textwidth]{figs/retuites_graph_que.png} % coloque o arquivo na pasta escolhida
%     \caption{Gráfico dos retuítes de tweets com desinformação em relação aos retuítes de cada
% cluster obtidos com termos-chave baseados em ``que'' - Mês de outubro/2022}
%     \label{fig:retuites-graph-que}
%     \legend{\footnotesize Fonte: elaboração própria.} % abnTeX2
% \end{figure}
% \begin{figure}[H] % ou [!htb] se preferir deixar o LaTeX decidir
%     \centering
%     \includegraphics[width=1\textwidth]{figs/retuites_graph_svm.png} % coloque o arquivo na pasta escolhida
%     \caption{Gráfico dos retuítes de tweets com desinformação em relação aos retuítes de cada
% cluster obtidos com termos-chave SVM - Mês de outubro/2022}
%     \label{fig:retuites-graph-svm}
%     \legend{\footnotesize Fonte: elaboração própria.} % abnTeX2
% \end{figure}

\begin{table}[H]
\centering
\caption{Termos-chave resultantes}
\label{tab:exemplo-6x5}
\renewcommand{\arraystretch}{0.9} % um pouco mais de altura nas linhas
\begin{tabularx}{\linewidth}{|>{\raggedright\arraybackslash}p{0.15\linewidth}|X|X|X|X|}
\hline
\textbf{Títulos das notícias} & \textbf{Termos Manuais} & \textbf{Termos SVM} & \textbf{Termos DistilBERT} & \textbf{Termos SBERT} \\
\hline
Vulnerabilida-des em urnas citadas em vídeo de 2014 já foram corrigidas & fraudar urnas, vídeo de Diego
Aranha, não testou as urnas, como
fiscalizar as urnas, Video viralizando
Sábado, não te como TSE Fraudar as
urnas & os problemas citados por ele na gravação já foram sanados pela justiça eleitoral, os problemas citados por ele na gravação já foram sanados pela justiça eleitoral, um vídeo de 2014 em & registra aleatoriamente os votos computados pelos eleitores, o tse (tribunal superior eleitoral) não testou a segurança das urnas para as eleições de 2022 & o tse (tribunal superior eleitoral) não testou a segurança das urnas para as eleições de 2022 \\
\hline
Apertar “confirma” durante tela “confira seu voto” na urna eletrônica anula voto é boato & TSE fraudar as urnas, fraudar
eleições, derrota antecipada,
fracasso eleitoral, Não votar nas
urnas eletrônicas, muito mais votos
registrados & estamos chegando na semana final da campanha eleitoral do primeiro turno, ao contrário, foi possível ver & apertar “confirma” durante a tela “confira seu voto” anula o voto, anulação é falsa & a tela em questão não tem qualquer relação com anulação \\
\hline
Correntes no WhatsApp e no Telegram mentem sobre o que eleitor pode ou não fazer no domingo & Apertar confira seu voto, perderá
voto, votos não computadorizados,
votos serão anulados, teclar ok ou
confirma & mesários mal-intencionados tentariam boicotar o pleito, deixando de entregar comprovantes de votação, de coletar as assinaturas no livro de registro & no telegram disseminam informações falsas sobre o & aos fatosf: compartilhe correntes de mensagens no whatsapp \\
\hline
Acusação de fraude eleitoral domina correntes de WhatsApp em grupos monitorados & FRAUD3 NA ELE1ÇÃ0,Bolso-naro
não pode deixar haver, Bolsonaro
não deixa ter segundo turno, Fraude
na eleição & esta reportagem foi feita numa colaboração entre agência pública, aos fatos & esta reportagem foi feita numa colaboração entre agência pública, aos fatos & esta reportagem foi feita numa colaboração entre agência pública, aos fatos \\
\hline
\end{tabularx}
\end{table}
