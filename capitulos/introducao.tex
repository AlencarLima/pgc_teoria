% ----------------------------------------------------------
% Introdução 
% Capítulo sem numeração, mas presente no Sumário
% ----------------------------------------------------------

\chapter[Introdução]{Introdução}
\label{cap:introducao}
% \addcontentsline{toc}{chapter}{Introdução}

A criação e disseminação da desinformação não são fenômenos recentes. Desde os tempos em que a comunicação se dava por jornais impressos, rádios, televisões ou até mesmo pela transmissão oral, já existiam tentativas de manipular ou distorcer fatos com diferentes intenções, podendo ser políticas, econômicas ou sociais. No entanto, o avanço tecnológico transformou profundamente esse cenário. A internet e, especialmente, as redes sociais, ampliaram exponencialmente o alcance e a velocidade com que conteúdos são compartilhados.

Com a popularização e o barateamento do acesso à internet, a sociedade passou a viver em um ambiente globalizado e hiperconectado, no qual o fluxo de informações é constante e instantâneo. Plataformas como \textit{WhatsApp}, \textit{Messenger}, \textit{blogs} e portais de notícias tornaram-se canais centrais para o consumo e a troca de conteúdo. Essa democratização da informação, embora traga benefícios, também intensificou o desafio de distinguir o que é verdadeiro do que é manipulador ou enganoso. O excesso de informações, algumas provenientes de fontes jornalísticas verificadas e outras de origem duvidosa, cria um ambiente em que o discernimento crítico se torna fundamental para evitar a propagação da desinformação e para possibilitar a identificação de termos, expressões e padrões linguísticos associados a esse fenômeno.

A situação torna-se ainda mais preocupante à medida que empresas, governos e até indivíduos começam a gerar e disseminar informações por meio de redes sociais para benefícios próprios. Desse modo, analisar e filtrar todo dado recebido, destacando termos e construções mais recorrentes em conteúdos desinformativos, pode-se tornar demorado e inviável, já que, aproximadamente, 6 bilhões de pessoas, o que representa cerca de 74\% da população mundial, possuem acesso à internet de acordo com os dados levantados pela União Internacional de Telecomunicações e representado na Figura~\ref{fig:pessoas_online}, ou seja, são possíveis disseminadores de desinformação, mesmo que não intencionalmente. Para lidar com tal situação, além da implementação de ferramentas capazes de discernir quanto às mensagens transmitidas, é necessário que haja um auxílio governamental de modo a limitar o compartilhamento de informações não verificadas, bem como incentivar o desenvolvimento de métodos de extração de termos e indícios linguísticos que ajudem a mapear e compreender a difusão da desinformação.

\begin{figure}[H] % ou [!htb] se preferir deixar o LaTeX decidir
    \centering
    \includegraphics[width=1\textwidth]{figs/pessoas_online.png} % coloque o arquivo na pasta escolhida
    \caption{Indivíduos usando a internet - Número de pessoas em bilhões por ano.}
    \label{fig:pessoas_online}
    \legend{\footnotesize Fonte: \cite{itu2025}} % abnTeX2
\end{figure}

Além do enfoque computacional, a disseminação de desinformação \textit{online} apresenta um desafio para diversas outras áreas científicas, sendo uma delas a área científica que envolve questões psicológicas. Muitas vezes, a dificuldade para diferenciar a verdade da ficção está relacionada à falta de precisão com que os indivíduos refletem sobre determinado assunto, podendo utilizar menos raciocínio caso a notícia confirme suas próprias ideias~\cite{pennycook2021}. Dessa forma, é notório que ocorre uma manipulação emocional para incentivar certos tipos de comportamentos que beneficiam o emissor de tais desinformações, tendo como exemplo manipulações com finalidades políticas capazes de proliferarem comportamentos agressivos e preconceituosos~\cite{souza2019}. Portanto, é possível notar que a vulnerabilidade do pensamento não racional humano pode ser explorada para influenciar comportamentos. Ao mesmo tempo, essa vulnerabilidade pode servir de indício para identificar padrões linguísticos e extrair termos característicos de mensagens manipulativas, já que conteúdos manipulativos tendem a conter informações que exploram o lado sentimental dos leitores.

A desordem informacional tornou-se um elemento estruturante da comunicação digital contemporânea, marcada pela crescimento acelerada de conteúdos verdadeiros, falsos e distorcidos em plataformas como o \textit{Twitter}~\cite{silva2020}. Durante a pandemia de COVID-19, essa dinâmica se intensificou e configurou a chamada infodemia, entendida como uma superabundância de informações que dificulta o reconhecimento de orientações confiáveis~\cite{opas2020}.

A classificação proposta por Wardle e Derakhshan~\cite{wardle2017}, posteriormente ampliada pela UNESCO~\cite{unesco2018}, estabelece três formas principais de distorção, informação incorreta, desinformação e má-informação, que ajudam a compreender a complexidade do fenômeno. No Brasil, o Tribunal Superior Eleitoral passou a empregar o termo “desinformação” de modo abrangente para abarcar diversas estratégias de manipulação de conteúdo, não restritas ao formato jornalístico característico das chamadas ``\textit{fake news}''~\cite{tresp2023}.

Pesquisas empíricas reforçam essa preocupação ao demonstrar que conteúdos enganosos tendem a se espalhar com maior velocidade e alcance do que informações verificadas~\cite{vosoughi2018,cinelli2020}, evidenciando que a lógica de funcionamento das redes sociais favorece sua difusão. Diante desse cenário, este trabalho adota “desinformação” como eixo central de análise, alinhando-se à literatura e às instituições que tratam o tema como parte de um desafio amplo para a comunicação pública e a governança democrática~\cite{garciasaiso2021}.

Com base na análise dos métodos de avaliação de veracidade atual, duas abordagens principais se destacam: a Abordagem Linguística e a Abordagem de Redes. A Abordagem Linguística foca na análise do conteúdo de mensagens enganosas, identificando padrões de linguagem que indicam engano, como o uso de pronomes, conjunções e palavras de emoção negativa. Por outro lado, a Abordagem de Redes utiliza informações de rede, como metadados de mensagens ou consultas estruturadas em redes de conhecimento, para calcular medidas agregadas de engano. ~\cite{ADDConroy} Ambas as abordagens geralmente incorporam técnicas de aprendizado de máquina para treinar classificadores adaptados à análise. No entanto, dado o foco deste trabalho, a Abordagem de Redes não será explorada, tendo ênfase na exploração das técnicas de Processamento de Linguagem Natural (PLN) para a detecção de desinformação intencionalmente falsa.

Também é essencial a elaboração de uma definição para fato. Para este estudo, será considerado uma afirmação ou proposição objetiva que pode ser verificada como verdadeira ou falsa com base em evidências disponíveis, sem depender de julgamentos subjetivos como relevância, importância editorial ou interpretações pessoais. Para ser classificada como fato, a afirmação deve ser suficientemente clara, específica e independente de contextos variáveis que possam influenciar sua interpretação. A verificabilidade de um fato depende da existência de métodos ou dados concretos que permitam sua avaliação por diferentes indivíduos ou organizações de maneira consistente e replicável~\cite{claimDetection}. 

%\section{Motivação}
\section{Objetivos}

\subsection{Objetivo Geral}
O objetivo geral deste trabalho é extrair, de forma automatizada, termos factuais presentes em notícias relevantes com conteúdos verificados por ``agências'' como Aos Fatos, Fatos ou fake, Uol confere e Estadão Verifica com conteúdos envolvendo urnas eletrônicas no Brasil, de modo a otimizar o processo de classificação desses conteúdos. Para isso, serão utilizadas técnicas de PLN, como modelos de \textit{transformers}, BERT, SVM e \textit{regex}. A partir dessa análise, serão apontados fatores que podem contribuir para o avanço da área de PLN e para a melhoria das ferramentas de detecção de desinformação.

\subsection{Objetivos Específicos}
Com o objetivo de delinear e alcançar o objetivo geral proposto, os seguintes objetivos específicos foram estabelecidos:
\begin{itemize}
    \item Analisar modelos relevantes por meio de revisão dos modelos de PLN usados em detecção de fatos relevantes.
    \item Aplicar modelos em dados verificados e ajustá-los para analisar textos em Português e adaptar para o contexto de desinformação.
    \item Definir e utilizar métricas apropriadas, como precisão, \textit{recall} e \textit{F1-score}, para avaliar o desempenho dos modelos aplicados.
    \item Coletar, analisar e avaliar os resultados obtidos, utilizando métricas de desempenho e parametrizando diferentes configurações.
    \item Comparar os resultados com pesquisas existentes, identificar diferenças.
    \item Sugerir possíveis melhorias e avanços com base nas comparações realizadas.
\end{itemize}

\section{Justificativa}
De acordo com uma pesquisa realizada pela \textit{PR Newswire}, aproximadamente 65\% das gerações \textit{Millennials} e Z preferem se comunicar com mais frequência por meio de ambientes digitais do que pessoalmente~\cite{prnews}. Este dado revela uma transformação significativa nos padrões de interação social, impulsionada pela popularização dos \textit{smartphones}, redes sociais e aplicativos de mensagens. Nesse contexto, essas gerações estão mais expostas a conteúdos que podem ser potencialmente falsos, especialmente na forma de textos. A ampla exposição a informações digitais e a velocidade com que elas se disseminam tornam a identificação de desinformação um desafio ainda maior.

Outro fator agravante é o fato de que, apesar de possuírem a obrigação de se atentarem à veracidade das notícias, nem mesmo
especialistas estão isentos de acreditarem em informações falsas. Em 2013, em um \textit{tweet} da
agência de notícias Associated Press, foi dito que houve uma suposta explosão que teria ferido Barack Obama, o que levou a uma perda de 130 bilhões de dólares em ações, tal valor sendo recuperado rapidamente após ser anunciado que a notícia era falsa ~\cite{impactFakeNews}. Entretanto, mesmo com a recuperação econômica rápida, pode-se notar que a disseminação de desinformação tem impactos em toda economia de um país. Desse modo, é inegável que a propagação de informação na internet deve receber atenção de autoridades públicas, empresariais e da comunidade científica.

Diante dessa realidade, é de extrema importância o desenvolvimento de ferramentas que possam tornar esses ambientes digitais mais seguros e menos suscetíveis à desinformação. A revisão e aprimoramento de técnicas para mitigar a disseminação de desinformação são essenciais para superar os desafios atuais. Em particular, o avanço das ferramentas de PLN desempenha um papel fundamental nesse contexto, já que permitem facilitar e otimizar processos que, sem elas, seriam mais custosos e menos precisos.

O processo de checagem de fatos em uma organização pode ser dividido em quatro etapas principais: (1) monitorar a mídia, capturando conteúdos como artigos, vídeos e imagens; (2) detectar afirmações verificáveis; (3) verificar as afirmações por meio de pesquisa detalhada; e (4) publicar os resultados das verificações. No entanto, a maior parte da pesquisa científica tem-se concentrado na etapa de verificação da veracidade, também conhecido como \textit{checking claims}, com estudos rotulados como detecção de \textit{fake news} ou desinformação, colocando em segundo plano etapas iniciais igualmente essenciais, como a detecção de afirmações~\cite{claimDetection}. 

Observa-se que grande parte das pesquisas em detecção automática de desinformação permanece centrada na formulação do problema como uma tarefa de classificação supervisionada, em geral binária ou multiclasse, aplicada diretamente à veracidade das notícias \cite{oshikawa2020survey}. Em contrapartida, etapas intermediárias do \textit{pipeline} de checagem, como a identificação sistemática de afirmações verificáveis, a seleção de trechos relevantes e a otimização dos modelos de linguagem utilizados nessa filtragem inicial, ainda recebem atenção mais limitada na literatura, surgindo apenas mais recentemente como objetos de estudo específicos em tarefas de \textit{claim detection} e normalização de afirmações \cite{claimDetection}. 
Essa lacuna torna-se ainda mais evidente no contexto de línguas de poucos recursos, como o português, em que há escassez de recursos anotados e de estudos sistemáticos voltados à detecção de desinformação e às etapas prévias de seleção de conteúdo. Portanto, é notória a necessidade de investigar precisamente esse elo intermediário do processo, propondo e avaliando estratégias de PLN para detecção automática de afirmações em português, com o objetivo de tornar o fluxo de \textit{fact-checking} mais eficiente, escalável e alinhado às necessidades práticas de organizações de checagem de fatos.

Automatizar essas etapas iniciais, especialmente a detecção de afirmações, é fundamental para alimentar o processo de verificação com entradas relevantes e gerenciar o volume de informações. Sem uma lista bem apurada de afirmações verificáveis, a etapa de determinação da veracidade não pode funcionar de forma eficaz. ~\cite{claimDetection} Portanto, integrar ferramentas automatizadas pode tornar o processo mais eficiente, reduzir a carga de trabalho dos verificadores e aumentar a qualidade e a agilidade na disseminação de informações confiáveis.

%sugestão
% \section{Estrutura da Monografia}


% SUGESTAO: Exemplo de estrutura da monografia:

% O presente relatório está estruturado da seguinte forma: o Capítulo~\ref{cap:fundamentacao_teorica} apresenta..., o Capítulo~\ref{cap:trabalhos_relacionados}... O Capítulo~\ref{cap:metodologia} ..., o Capítulo~\ref{cap:resultados} .... Finalmente, o Capítulo~\ref{cap:conclusao} apresenta ...
