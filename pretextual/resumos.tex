% ---
% RESUMOS
% ---

% RESUMO em português
\setlength{\absparsep}{18pt} % ajusta o espaçamento dos parágrafos do resumo
\begin{resumo}

A crescente disseminação de desinformação em ambientes digitais, aliada à velocidade com que conteúdos circulam em plataformas e redes sociais, transformou-se em um desafio central para a sociedade contemporânea. Neste contexto, o trabalho analisa empiricamente um conjunto de processos de pré-tratamento e filtragem textual, em particular, sumarização extrativa automática, segmentação guiada por conjunções e detecção de afirmações factuais, aplicados à análise de desinformação. No primeiro estágio, três modelos de sumarização baseada em \textit{transformers} (BERT-base, DistilBERT e SBERT-MiniLM) foram comparados quanto à capacidade de reduzir ruído preservando trechos factuais. Os resultados mostram que todos produziram resumos em torno de 25\%--27\% do texto original, mas o SBERT-MiniLM apresentou melhor equilíbrio entre retenção de tópicos centrais, similaridade semântica e custo computacional, enquanto o DistilBERT se mostrou mais conservador na redução de conteúdo factual. Em seguida, avaliou-se uma estratégia de segmentação baseada na conjunção ``que'', aplicada a notícias de checagem e a \textit{clusters} de \textit{tweets}. Essa abordagem recuperou conjuntos maiores e mais pertinentes de trechos do que termos-chave definidos manualmente e superou métodos baseados apenas em aspas, que retornaram poucos segmentos relevantes. Por fim, investigou-se o uso de modelos para identificação automática de afirmações factuais, com o XLM-R-Large-\textit{ClaimDetection} e um classificador SVM atuando como filtros sobre grandes volumes de texto. O XLM-R-Large obteve acurácia de 0{,}88 em português e elevado \textit{recall} para sentenças factuais importantes, enquanto o SVM apresentou desempenho moderado, contribuindo para reduzir o volume de conteúdo a ser inspecionado manualmente. Ademais, esses processos permitiram comparar diferentes estratégias de rotulagem de desinformação em \textit{tweets} e retuítes, evidenciando o \textit{trade-off} entre métodos mais conservadores, que se aproximam do padrão manual, e abordagens mais assertivas, que ampliam a cobertura de conteúdo potencialmente desinformativo ao custo de maior risco de rotulagem excessiva de \textit{tweets} não relevantes. Os resultados obtidos oferecem subsídios para o aperfeiçoamento de ferramentas computacionais voltadas ao enfrentamento de usos maliciosos de dados textuais.

\textbf{Palavras-chaves}: Desinformação, sumarização extrativa automática, extração de termos factuais, segmentação textual, aprendizado de máquina.
\end{resumo}

% ABSTRACT in english
\begin{resumo}[Abstract]
 \begin{otherlanguage*}{english}
    The growing spread of disinformation in digital environments, together with the speed at which content circulates on platforms and social networks, has become a central challenge for contemporary society. In this context, this work empirically analyzes a set of text preprocessing and filtering procedures, in particular, automatic extractive summarization, conjunction-based segmentation, and factual claim detection, applied to disinformation analysis.
    In the first stage, three transformer-based summarization models (BERT-base, DistilBERT, and SBERT-MiniLM) were compared in terms of their ability to reduce noise while preserving factual segments. The results show that all models produced summaries of about 25\%–27\% of the original text, but SBERT-MiniLM achieved the best balance between topic retention, semantic similarity, and computational cost, whereas DistilBERT behaved more conservatively in the reduction of factual content. Next, a segmentation strategy based on the conjunction ``that'' was evaluated on fact-checking news articles and on \textit{tweet} clusters. This approach recovered larger and more pertinent sets of segments than manually defined keywords and outperformed quote-based methods, which returned few relevant fragments.
    Finally, we investigated the use of models for automatic detection of factual claims, with XLM-R-Large-\textit{ClaimDetection} and an SVM classifier acting as filters over large text collections. XLM-R-Large achieved an accuracy of 0.88 in Portuguese with high recall for important factual sentences, while the SVM model obtained moderate performance, helping to reduce the amount of content that requires manual inspection. Taken together, these processes enabled the comparison of different labeling strategies for disinformation in tweets and retweets, highlighting the trade-off between more conservative methods, closer to manual annotation, and more assertive approaches that expand coverage at the cost of a a higher risk of excessively labeling non-relevant \textit{tweets}t. The results provide input for improving computational tools aimed at countering malicious uses of textual data.

   \vspace{\onelineskip}
 
   \noindent 
   \textbf{Keywords}: Disinformation, automatic extractive summarization, 
factual terms, text segmentation, machine learning.
 \end{otherlanguage*}
\end{resumo}
